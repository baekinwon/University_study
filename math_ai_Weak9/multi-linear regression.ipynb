{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1QWth6_9kJDRl94EEHsxmuL2S5Q7JpEud","authorship_tag":"ABX9TyPrcp39zypeDiDoIE/7+ib2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"szFnOxxZIxll","executionInfo":{"status":"ok","timestamp":1684820747092,"user_tz":-540,"elapsed":11432,"user":{"displayName":"백인원","userId":"17179721393715267006"}},"outputId":"5c7b6b5a-f19e-41cf-9873-82e10c145b74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t0EvjexMGVaQ","executionInfo":{"status":"ok","timestamp":1684820813519,"user_tz":-540,"elapsed":2132,"user":{"displayName":"백인원","userId":"17179721393715267006"}},"outputId":"282634c2-dd4b-4c0a-e14f-f74f221ba1c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["3821.841406021638 [[0.11502261]\n"," [0.64600351]\n"," [0.49016282]] [0.60753991]\n","0 559593702.3073097 [[ 98.73563984]\n"," [ 99.6528216 ]\n"," [102.13997272]] [-477.10062096]\n","400 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","800 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","1200 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","1600 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","2000 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","2400 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","2800 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","3200 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","3600 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","4000 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","4400 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","4800 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","5200 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","5600 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","6000 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","6400 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","6800 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","7200 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","7600 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","8000 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","8400 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","8800 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","9200 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","9600 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n","10000 2.1645164907383327e+29 [[1.87350847e+12]\n"," [1.87347783e+12]\n"," [2.00756687e+12]] [-69449398.97562096]\n"]}],"source":["import numpy as np\n","\n","# 학습데이터 준비\n","loaded_data = np.loadtxt('/content/drive/MyDrive/경기과대/인공지능 수학/11주차/score.csv',delimiter=',',dtype=np.float32) # n행 4열의 데이터임 마지막 열은 타겟 데이터\n","\n","x_data = loaded_data[:,0:-1] # 1열부터 마지막 열 전까지 모든 행 가져옴\n","t_data = loaded_data[:,[-1]] # 마지막 열 모든 행 가져옴\n","\n","# 임의의 직선 y = Wx+b 정의(임의의 값으로 가중치 w, 바이어스 b 초기화) y = w_1x_1+w_2x_2+w_3x_3+b\n","W = np.random.rand(3,1) # 입력 데이터 초기화 -> 3행 1열\n","b = np.random.rand(1) # 정답 데이터 초기화 -> 스칼라 값\n","\n","# 손실함수 l(W,b) 정의 (학습을 위한 정의)\n","def loss_func(x,t):\n","    y = np.dot(x,W)+b # dot은 행렬 곱\n","    return (np.sum((t-y)**2)) / (len(x))\n","\n","# 수치미분 numerical_derivative 및 utility 함수 정의 \n","def numerical_derivative(f,x): # f는 미분하고자 하는 다변수 함수, x는 모든 변수를 포함하고 있는 numpy 객체(배열, 행렬)등\n","    delta_x = 1e-5 #lim에 해당되는 작은 값\n","    grad = np.zeros_like(x) # 계산된 수치미분 값 저장 변수\n","\n","    it = np.nditer(x, flags =['multi_index'],op_flags=['readwrite'])# 모든 입력변수에 대해 편미분하기 위해 사용\n","    while not it.finished:\n","        idx = it.multi_index  # x에대한 편미분 후 y에 대한 편미분 실행  [1.0,2.0]이라면 1.0 편미분 후 2.0 편미분\n","        \n","        tmp_val = x[idx] # numpy 타입은 mutable이므로 원래 값 보관\n","        x[idx] = float(tmp_val)+delta_x #하나의 변수에 대해 수치미분 계산\n","        fx1 = f(x) # f(x+delta_x) 전체에 대해 계산해야 하기 때문에 x[idx]가 아닌 x를 넣어줌\n","\n","        x[idx] = tmp_val - delta_x\n","        fx2=f(x) # f(x-delta_x)\n","        grad[idx] = (fx1-fx2)/(2*delta_x)\n","\n","        x[idx] = tmp_val\n","        it.iternext()\n","\n","    return grad\n","\n","def loss_val(x,t):  # 손실함수값 확인 코드\n","    y = np.dot(x,W)+b # dot은 행렬 곱\n","    return (np.sum((t-y)**2)) / (len(x))\n","\n","def predict(x): # 예측값 확인 코드\n","    y = np.dot(x,W)+b \n","    return y\n","\n","# 학습률 초기화 및 손실함수가 최소가 될 때까지 W,b 업데이트\n","learning_rate = 1e-2 \n","\n","f = lambda x: loss_func(x_data,t_data) # loss_func에 x_data,t_data가 들어감\n","print(loss_val(x_data,t_data),W,b)\n","\n","for step in range(10001):\n","    W-= learning_rate * numerical_derivative(f,W) # w에 대한 수치미분\n","    b-= learning_rate * numerical_derivative(f,b) # b에 대한 수치미분\n","\n","    if(step % 400==0):\n","        print(step,loss_val(x_data,t_data),W,b)\n","# 결과값 w 3개는 각 열에 대한 w값임"]},{"cell_type":"code","source":["predict([96,93,95])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Ecq6vQ-Sg9N","executionInfo":{"status":"ok","timestamp":1684823279116,"user_tz":-540,"elapsed":446,"user":{"displayName":"백인원","userId":"17179721393715267006"}},"outputId":"7a05fe3e-b926-4cd2-b919-0f03d2d3459d"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([5.44809034e+14])"]},"metadata":{},"execution_count":9}]}]}